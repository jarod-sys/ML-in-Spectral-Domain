{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "528dbf2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\franc\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import plot_model\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.utils import plot_model\n",
    "from SpectralLayer import Spectral\n",
    "from tensorflow.keras.layers import Dense,Dropout\n",
    "import pandas as pd\n",
    "from typing import Dict,List, Tuple, Any\n",
    "from Jlayers import*\n",
    "import seaborn as sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "073950b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "flat_train = np.reshape(x_train, [x_train.shape[0], 28 * 28])\n",
    "flat_test = np.reshape(x_test, [x_test.shape[0], 28 * 28])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f2aaff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=20\n",
    "\n",
    "accuracy=list()\n",
    "    \n",
    "Index=[\"Contraint_NN\",\"Train_D\",\"Uncontrained_NN\",\"Train_D_and_Phi\"]\n",
    "Columns=[\"Linear_Wide\",\"Linear_Deep\",\"Non_Linear\"]\n",
    "\n",
    "precision: Dict[str,Dict[str,List]]=dict()\n",
    "precision={\"Contraint_NN\":{\"Linear_Wide\":[],\"Linear_Deep\":[],\"Non_Linear\":[]},\n",
    "           \"Train_D\":{\"Linear_Wide\":[],\"Linear_Deep\":[],\"Non_Linear\":[]},\n",
    "           \"Uncontrained_NN\":{\"Linear_Wide\":[],\"Linear_Deep\":[],\"Non_Linear\":[]},\n",
    "           \"Train_D_and_Phi\":{\"Linear_Wide\":[],\"Linear_Deep\":[],\"Non_Linear\":[]}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef829b7f",
   "metadata": {},
   "source": [
    "# 1- LinearWide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0246a61",
   "metadata": {},
   "source": [
    "# Diag trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f59075c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\franc\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\franc\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\franc\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3645 - accuracy: 0.8941\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3722 - accuracy: 0.8938\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3583 - accuracy: 0.8968\n"
     ]
    }
   ],
   "source": [
    "accuracy=list()\n",
    "for i in range(3):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Input(shape=(28 * 28), dtype='float32'))\n",
    "    model.add(Spectral(1000, is_base_trainable=False, is_diag_start_trainable=False,is_diag_end_trainable=True, use_bias=False))\n",
    "    model.add(Spectral(10, is_base_trainable=False,is_diag_start_trainable=False,is_diag_end_trainable=True, use_bias=False, activation='softmax'))\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.005)\n",
    "    model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(flat_train, y_train, batch_size=200, epochs=epochs,verbose=0,validation_data=(flat_test, y_test))\n",
    "    accuracy.append(model.evaluate(flat_test,y_test,batch_size=32,verbose=\"auto\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74397050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Contraint_NN': {'Linear_Wide': [], 'Linear_Deep': [], 'Non_Linear': []},\n",
       " 'Train_D': {'Linear_Wide': [0.8949000040690104],\n",
       "  'Linear_Deep': [],\n",
       "  'Non_Linear': []},\n",
       " 'Uncontrained_NN': {'Linear_Wide': [], 'Linear_Deep': [], 'Non_Linear': []},\n",
       " 'Train_D_and_Phi': {'Linear_Wide': [], 'Linear_Deep': [], 'Non_Linear': []}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision[Index[1]][Columns[0]].append(pd.Series(accuracy).mean())\n",
    "precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bc43e4",
   "metadata": {},
   "source": [
    "# Diag and Base trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43ffbb06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3073 - accuracy: 0.9173\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2979 - accuracy: 0.9187\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3015 - accuracy: 0.9206\n"
     ]
    }
   ],
   "source": [
    "accuracy=list()\n",
    "for i in range(3):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Input(shape=(28 * 28), dtype='float32'))\n",
    "    model.add(Spectral(1000, is_base_trainable=True, is_diag_start_trainable=False,is_diag_end_trainable=True, use_bias=False))\n",
    "    model.add(Spectral(10, is_base_trainable=True,is_diag_start_trainable=False,is_diag_end_trainable=True, use_bias=False, activation='softmax'))\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.005)\n",
    "    model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(flat_train, y_train, batch_size=200, epochs=epochs,verbose=0,validation_data=(flat_test, y_test))\n",
    "    accuracy.append(model.evaluate(flat_test,y_test,batch_size=32,verbose=\"auto\")[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64520d80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Contraint_NN': {'Linear_Wide': [], 'Linear_Deep': [], 'Non_Linear': []},\n",
       " 'Train_D': {'Linear_Wide': [0.8949000040690104],\n",
       "  'Linear_Deep': [],\n",
       "  'Non_Linear': []},\n",
       " 'Uncontrained_NN': {'Linear_Wide': [], 'Linear_Deep': [], 'Non_Linear': []},\n",
       " 'Train_D_and_Phi': {'Linear_Wide': [0.9188666542371114],\n",
       "  'Linear_Deep': [],\n",
       "  'Non_Linear': []}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision[Index[3]][Columns[0]].append(pd.Series(accuracy).mean())\n",
    "precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57454a96",
   "metadata": {},
   "source": [
    "# Unconstraint NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cae7fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3464 - accuracy: 0.9107\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3506 - accuracy: 0.9137\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3547 - accuracy: 0.9113\n"
     ]
    }
   ],
   "source": [
    "accuracy=list()\n",
    "for i in range(3):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Input(shape=(28 * 28), dtype='float32'))\n",
    "    model.add(Dense(1000,use_bias=False))\n",
    "    model.add(Dense(10, use_bias=False, activation='softmax'))\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.005)\n",
    "    model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(flat_train, y_train, batch_size=200, epochs=epochs,verbose=0,validation_data=(flat_test, y_test))\n",
    "    accuracy.append(model.evaluate(flat_test,y_test,batch_size=32,verbose=\"auto\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3183a34e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Contraint_NN': {'Linear_Wide': [], 'Linear_Deep': [], 'Non_Linear': []},\n",
       " 'Train_D': {'Linear_Wide': [0.8949000040690104],\n",
       "  'Linear_Deep': [],\n",
       "  'Non_Linear': []},\n",
       " 'Uncontrained_NN': {'Linear_Wide': [0.911900003751119],\n",
       "  'Linear_Deep': [],\n",
       "  'Non_Linear': []},\n",
       " 'Train_D_and_Phi': {'Linear_Wide': [0.9188666542371114],\n",
       "  'Linear_Deep': [],\n",
       "  'Non_Linear': []}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision[Index[2]][Columns[0]].append(pd.Series(accuracy).mean())\n",
    "precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fcafc7",
   "metadata": {},
   "source": [
    "# Constraint NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e7cc8e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 7ms/step - loss: 0.5691 - accuracy: 0.8322\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.5060 - accuracy: 0.8481\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.5705 - accuracy: 0.8310\n"
     ]
    }
   ],
   "source": [
    "accuracy=list()\n",
    "for i in range(3):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Input(shape=(28 * 28), dtype='float32'))\n",
    "    model.add(SimpleLayer(1000,number_params_train=1000,activation=None))\n",
    "    model.add(SimpleLayer(10,number_params_train=10,activation='softmax'))\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.005)\n",
    "    model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(flat_train, y_train, batch_size=200, epochs=epochs,verbose=0,validation_data=(flat_test, y_test))\n",
    "    accuracy.append(model.evaluate(flat_test,y_test,batch_size=32,verbose=\"auto\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad32d724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Contraint_NN': {'Linear_Wide': [0.8370999892552694],\n",
       "  'Linear_Deep': [],\n",
       "  'Non_Linear': []},\n",
       " 'Train_D': {'Linear_Wide': [0.8949000040690104],\n",
       "  'Linear_Deep': [],\n",
       "  'Non_Linear': []},\n",
       " 'Uncontrained_NN': {'Linear_Wide': [0.911900003751119],\n",
       "  'Linear_Deep': [],\n",
       "  'Non_Linear': []},\n",
       " 'Train_D_and_Phi': {'Linear_Wide': [0.9188666542371114],\n",
       "  'Linear_Deep': [],\n",
       "  'Non_Linear': []}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision[Index[0]][Columns[0]].append(pd.Series(accuracy).mean())\n",
    "precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa86ef14",
   "metadata": {},
   "source": [
    "# 2- Linear deep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32ea620",
   "metadata": {},
   "source": [
    "# Diag trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63f78200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3387 - accuracy: 0.9035\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3355 - accuracy: 0.9050\n"
     ]
    }
   ],
   "source": [
    "accuracy=list()\n",
    "for i in range(2):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Input(shape=(28 * 28), dtype='float32'))\n",
    "    model.add(Spectral(1000, is_base_trainable=False, is_diag_start_trainable=False,is_diag_end_trainable=True, use_bias=False))\n",
    "    model.add(Spectral(120, is_base_trainable=False, is_diag_start_trainable=False,is_diag_end_trainable=True, use_bias=False))\n",
    "    model.add(Spectral(10, is_base_trainable=False,is_diag_start_trainable=False,is_diag_end_trainable=True, use_bias=False, activation='softmax'))\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.005)\n",
    "    model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(flat_train, y_train, batch_size=200, epochs=epochs,verbose=0,validation_data=(flat_test, y_test))\n",
    "    accuracy.append(model.evaluate(flat_test,y_test,batch_size=32,verbose=\"auto\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3beab1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Contraint_NN': {'Linear_Wide': [0.8370999892552694],\n",
       "  'Linear_Deep': [],\n",
       "  'Non_Linear': []},\n",
       " 'Train_D': {'Linear_Wide': [0.8949000040690104],\n",
       "  'Linear_Deep': [0.9042499959468842],\n",
       "  'Non_Linear': []},\n",
       " 'Uncontrained_NN': {'Linear_Wide': [0.911900003751119],\n",
       "  'Linear_Deep': [],\n",
       "  'Non_Linear': []},\n",
       " 'Train_D_and_Phi': {'Linear_Wide': [0.9188666542371114],\n",
       "  'Linear_Deep': [],\n",
       "  'Non_Linear': []}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision[Index[1]][Columns[1]].append(pd.Series(accuracy).mean())\n",
    "precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0780fa",
   "metadata": {},
   "source": [
    "# Diag and base trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a4e1c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2945 - accuracy: 0.9216\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2895 - accuracy: 0.9221\n"
     ]
    }
   ],
   "source": [
    "accuracy=list()\n",
    "for i in range(2):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Input(shape=(28 * 28), dtype='float32'))\n",
    "    model.add(Spectral(1000, is_base_trainable=True, is_diag_start_trainable=False,is_diag_end_trainable=True, use_bias=False))\n",
    "    model.add(Spectral(120, is_base_trainable=True, is_diag_start_trainable=False,is_diag_end_trainable=True, use_bias=False))\n",
    "    model.add(Spectral(10, is_base_trainable=True,is_diag_start_trainable=False,is_diag_end_trainable=True, use_bias=False, activation='softmax'))\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.005)\n",
    "    model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(flat_train, y_train, batch_size=200, epochs=epochs,verbose=0,validation_data=(flat_test, y_test))\n",
    "    accuracy.append(model.evaluate(flat_test,y_test,batch_size=32,verbose=\"auto\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98d74e24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Contraint_NN': {'Linear_Wide': [0.8370999892552694],\n",
       "  'Linear_Deep': [],\n",
       "  'Non_Linear': []},\n",
       " 'Train_D': {'Linear_Wide': [0.8949000040690104],\n",
       "  'Linear_Deep': [0.9042499959468842],\n",
       "  'Non_Linear': []},\n",
       " 'Uncontrained_NN': {'Linear_Wide': [0.911900003751119],\n",
       "  'Linear_Deep': [],\n",
       "  'Non_Linear': []},\n",
       " 'Train_D_and_Phi': {'Linear_Wide': [0.9188666542371114],\n",
       "  'Linear_Deep': [0.9218499958515167],\n",
       "  'Non_Linear': []}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision[Index[3]][Columns[1]].append(pd.Series(accuracy).mean())\n",
    "precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31fd4c5",
   "metadata": {},
   "source": [
    "# Uncontraint NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de32411d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3262 - accuracy: 0.9145\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3408 - accuracy: 0.9135\n"
     ]
    }
   ],
   "source": [
    "accuracy=list()\n",
    "for i in range(2):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Input(shape=(28 * 28), dtype='float32'))\n",
    "    model.add(Dense(1000,use_bias=False))\n",
    "    model.add(Dense(120,use_bias=False))\n",
    "    model.add(Dense(10, use_bias=False, activation='softmax'))\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.005)\n",
    "    model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(flat_train, y_train, batch_size=200, epochs=epochs,verbose=0,validation_data=(flat_test, y_test))\n",
    "    accuracy.append(model.evaluate(flat_test,y_test,batch_size=32,verbose=\"auto\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0fb3d98c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Contraint_NN': {'Linear_Wide': [0.8370999892552694],\n",
       "  'Linear_Deep': [],\n",
       "  'Non_Linear': []},\n",
       " 'Train_D': {'Linear_Wide': [0.8949000040690104],\n",
       "  'Linear_Deep': [0.9042499959468842],\n",
       "  'Non_Linear': []},\n",
       " 'Uncontrained_NN': {'Linear_Wide': [0.911900003751119],\n",
       "  'Linear_Deep': [0.914000004529953],\n",
       "  'Non_Linear': []},\n",
       " 'Train_D_and_Phi': {'Linear_Wide': [0.9188666542371114],\n",
       "  'Linear_Deep': [0.9218499958515167],\n",
       "  'Non_Linear': []}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision[Index[2]][Columns[1]].append(pd.Series(accuracy).mean())\n",
    "precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b1a396",
   "metadata": {},
   "source": [
    "# Contraint NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17511ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 8ms/step - loss: 0.4715 - accuracy: 0.8599\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.4682 - accuracy: 0.8600\n"
     ]
    }
   ],
   "source": [
    "accuracy=list()\n",
    "for i in range(2):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Input(shape=(28 * 28), dtype='float32'))\n",
    "    model.add(SimpleLayer(1000,number_params_train=1000,activation=None))\n",
    "    model.add(SimpleLayer(120,number_params_train=120,activation=None))\n",
    "    model.add(SimpleLayer(10,number_params_train=10,activation='softmax'))\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.005)\n",
    "    model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(flat_train, y_train, batch_size=200, epochs=epochs,verbose=0,validation_data=(flat_test, y_test))\n",
    "    accuracy.append(model.evaluate(flat_test,y_test,batch_size=32,verbose=\"auto\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b688b13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Contraint_NN': {'Linear_Wide': [0.8370999892552694],\n",
       "  'Linear_Deep': [0.8599500060081482],\n",
       "  'Non_Linear': []},\n",
       " 'Train_D': {'Linear_Wide': [0.8949000040690104],\n",
       "  'Linear_Deep': [0.9042499959468842],\n",
       "  'Non_Linear': []},\n",
       " 'Uncontrained_NN': {'Linear_Wide': [0.911900003751119],\n",
       "  'Linear_Deep': [0.914000004529953],\n",
       "  'Non_Linear': []},\n",
       " 'Train_D_and_Phi': {'Linear_Wide': [0.9188666542371114],\n",
       "  'Linear_Deep': [0.9218499958515167],\n",
       "  'Non_Linear': []}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision[Index[0]][Columns[1]].append(pd.Series(accuracy).mean())\n",
    "precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01443e4e",
   "metadata": {},
   "source": [
    "# 3-Non linear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688c7952",
   "metadata": {},
   "source": [
    "# Diag trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4c5e840d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2866 - accuracy: 0.9166\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2808 - accuracy: 0.9176\n"
     ]
    }
   ],
   "source": [
    "accuracy=list()\n",
    "for i in range(2):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Input(shape=(28 * 28), dtype='float32'))\n",
    "    model.add(Spectral(1000, is_base_trainable=False, is_diag_start_trainable=False,is_diag_end_trainable=True, use_bias=False))\n",
    "    model.add(Spectral(120, is_base_trainable=False, is_diag_start_trainable=False,is_diag_end_trainable=True, use_bias=False, activation='ReLU'))\n",
    "    model.add(Spectral(10, is_base_trainable=False,is_diag_start_trainable=False,is_diag_end_trainable=True, use_bias=False, activation='softmax'))\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "    model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(flat_train, y_train, batch_size=200, epochs=epochs,verbose=0,validation_data=(flat_test, y_test))\n",
    "    accuracy.append(model.evaluate(flat_test,y_test,batch_size=32,verbose=\"auto\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f1f59d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Contraint_NN': {'Linear_Wide': [0.8370999892552694],\n",
       "  'Linear_Deep': [0.8599500060081482],\n",
       "  'Non_Linear': []},\n",
       " 'Train_D': {'Linear_Wide': [0.8949000040690104],\n",
       "  'Linear_Deep': [0.9042499959468842],\n",
       "  'Non_Linear': [0.9170999825000763]},\n",
       " 'Uncontrained_NN': {'Linear_Wide': [0.911900003751119],\n",
       "  'Linear_Deep': [0.914000004529953],\n",
       "  'Non_Linear': []},\n",
       " 'Train_D_and_Phi': {'Linear_Wide': [0.9188666542371114],\n",
       "  'Linear_Deep': [0.9218499958515167],\n",
       "  'Non_Linear': []}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision[Index[1]][Columns[2]].append(pd.Series(accuracy).mean())\n",
    "precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e345edf3",
   "metadata": {},
   "source": [
    "# Diag and base trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8fac8f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2036 - accuracy: 0.9653\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1888 - accuracy: 0.9662\n"
     ]
    }
   ],
   "source": [
    "accuracy=list()\n",
    "for i in range(2):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Input(shape=(28 * 28), dtype='float32'))\n",
    "    model.add(Spectral(1000, is_base_trainable=True, is_diag_start_trainable=False,is_diag_end_trainable=True, use_bias=False))\n",
    "    model.add(Spectral(120, is_base_trainable=True, is_diag_start_trainable=False,is_diag_end_trainable=True, use_bias=False,activation='ReLU'))\n",
    "    model.add(Spectral(10, is_base_trainable=True,is_diag_start_trainable=False,is_diag_end_trainable=True, use_bias=False, activation='softmax'))\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "    model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(flat_train, y_train, batch_size=200, epochs=epochs,verbose=0,validation_data=(flat_test, y_test))\n",
    "    accuracy.append(model.evaluate(flat_test,y_test,batch_size=32,verbose=\"auto\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9a46d115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Contraint_NN': {'Linear_Wide': [0.8370999892552694],\n",
       "  'Linear_Deep': [0.8599500060081482],\n",
       "  'Non_Linear': []},\n",
       " 'Train_D': {'Linear_Wide': [0.8949000040690104],\n",
       "  'Linear_Deep': [0.9042499959468842],\n",
       "  'Non_Linear': [0.9170999825000763]},\n",
       " 'Uncontrained_NN': {'Linear_Wide': [0.911900003751119],\n",
       "  'Linear_Deep': [0.914000004529953],\n",
       "  'Non_Linear': []},\n",
       " 'Train_D_and_Phi': {'Linear_Wide': [0.9188666542371114],\n",
       "  'Linear_Deep': [0.9218499958515167],\n",
       "  'Non_Linear': [0.9657500088214874]}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision[Index[3]][Columns[2]].append(pd.Series(accuracy).mean())\n",
    "precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86a6103",
   "metadata": {},
   "source": [
    "# Uncontraint NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6fe4031f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3736 - accuracy: 0.9298\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.5730 - accuracy: 0.9150\n"
     ]
    }
   ],
   "source": [
    "accuracy=list()\n",
    "for i in range(2):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Input(shape=(28 * 28), dtype='float32'))\n",
    "    model.add(Dense(1000,use_bias=False))\n",
    "    model.add(Dense(120,use_bias=False, activation='ReLU'))\n",
    "    model.add(Dense(10, use_bias=False, activation='softmax'))\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "    model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(flat_train, y_train, batch_size=200, epochs=epochs,verbose=0,validation_data=(flat_test, y_test))\n",
    "    accuracy.append(model.evaluate(flat_test,y_test,batch_size=32,verbose=\"auto\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a86b55f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Contraint_NN': {'Linear_Wide': [0.8370999892552694],\n",
       "  'Linear_Deep': [0.8599500060081482],\n",
       "  'Non_Linear': []},\n",
       " 'Train_D': {'Linear_Wide': [0.8949000040690104],\n",
       "  'Linear_Deep': [0.9042499959468842],\n",
       "  'Non_Linear': [0.9170999825000763]},\n",
       " 'Uncontrained_NN': {'Linear_Wide': [0.911900003751119],\n",
       "  'Linear_Deep': [0.914000004529953],\n",
       "  'Non_Linear': [0.9223999977111816]},\n",
       " 'Train_D_and_Phi': {'Linear_Wide': [0.9188666542371114],\n",
       "  'Linear_Deep': [0.9218499958515167],\n",
       "  'Non_Linear': [0.9657500088214874]}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision[Index[2]][Columns[2]].append(pd.Series(accuracy).mean())\n",
    "precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4427fe0d",
   "metadata": {},
   "source": [
    "# contraint NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dac29825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 8ms/step - loss: 0.4580 - accuracy: 0.8641\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.4635 - accuracy: 0.8645\n"
     ]
    }
   ],
   "source": [
    "accuracy=list()\n",
    "for i in range(2):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Input(shape=(28 * 28), dtype='float32'))\n",
    "    model.add(SimpleLayer(1000,number_params_train=1000,activation=None))\n",
    "    model.add(SimpleLayer(120,number_params_train=120,activation=\"ReLU\"))\n",
    "    model.add(SimpleLayer(10,number_params_train=10,activation='softmax'))\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "    model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(flat_train, y_train, batch_size=200, epochs=epochs,verbose=0,validation_data=(flat_test, y_test))\n",
    "    accuracy.append(model.evaluate(flat_test,y_test,batch_size=32,verbose=\"auto\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5bd22a10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Contraint_NN': {'Linear_Wide': [0.8370999892552694],\n",
       "  'Linear_Deep': [0.8599500060081482],\n",
       "  'Non_Linear': [0.8642999827861786]},\n",
       " 'Train_D': {'Linear_Wide': [0.8949000040690104],\n",
       "  'Linear_Deep': [0.9042499959468842],\n",
       "  'Non_Linear': [0.9170999825000763]},\n",
       " 'Uncontrained_NN': {'Linear_Wide': [0.911900003751119],\n",
       "  'Linear_Deep': [0.914000004529953],\n",
       "  'Non_Linear': [0.9223999977111816]},\n",
       " 'Train_D_and_Phi': {'Linear_Wide': [0.9188666542371114],\n",
       "  'Linear_Deep': [0.9218499958515167],\n",
       "  'Non_Linear': [0.9657500088214874]}}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision[Index[0]][Columns[2]].append(pd.Series(accuracy).mean())\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7ef6bbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Table=pd.DataFrame(precision[Index[0]],index=[Index[0]])\n",
    "Table1=pd.DataFrame(precision[Index[1]],index=[Index[1]])\n",
    "Table2=pd.DataFrame(precision[Index[2]],index=[Index[2]])\n",
    "Table3=pd.DataFrame(precision[Index[3]],index=[Index[3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eb7a4a3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Linear_Wide</th>\n",
       "      <th>Linear_Deep</th>\n",
       "      <th>Non_Linear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Contraint_NN</th>\n",
       "      <td>0.837100</td>\n",
       "      <td>0.85995</td>\n",
       "      <td>0.86430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train_D</th>\n",
       "      <td>0.894900</td>\n",
       "      <td>0.90425</td>\n",
       "      <td>0.91710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uncontrained_NN</th>\n",
       "      <td>0.911900</td>\n",
       "      <td>0.91400</td>\n",
       "      <td>0.92240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train_D_and_Phi</th>\n",
       "      <td>0.918867</td>\n",
       "      <td>0.92185</td>\n",
       "      <td>0.96575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Linear_Wide  Linear_Deep  Non_Linear\n",
       "Contraint_NN        0.837100      0.85995     0.86430\n",
       "Train_D             0.894900      0.90425     0.91710\n",
       "Uncontrained_NN     0.911900      0.91400     0.92240\n",
       "Train_D_and_Phi     0.918867      0.92185     0.96575"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Average=pd.concat([Table,Table1,Table2,Table3],axis=0)\n",
    "Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "802eeae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataFrame_tolatex(df=None,*args):\n",
    "\n",
    "        file=df.to_latex()\n",
    "        file=file.replace(\"\\\\\", \"\\\\\\\\\")\n",
    "        file=file.replace(\"%\", \"\\%\")\n",
    "        file=file.replace(\"\\\\toprule\", \"toprule\")\n",
    "        file=file.replace(\"\\\\midrule\", \"midrule\")\n",
    "        file=file.replace(\"\\\\bottomrule\", \"bottomrule\")\n",
    "        file=file.replace(\"\\\\begin\", \"begin\")\n",
    "        file=file.replace(\"\\\\end\", \"end\")\n",
    "        with open(\"latex.txt\",\"w+\") as latex_file:\n",
    "            latex_file.write(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d43c608f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrame_tolatex(df=Average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8925b8a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
